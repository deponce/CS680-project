{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "SSK9j1V6wRL_",
    "outputId": "5c588fa4-4a49-401e-e4bf-24903b7e6a92"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.__version__\n",
    "CUDA_VISIBLE_DEVICES=2\n",
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WhKQE4f6wRMF",
    "outputId": "788105da-7db1-45a0-9353-9c4cb9a02dd9"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount(\"/content/drive\")\n",
    "#import os\n",
    "#os.chdir(os.path.join(\"/\", \"content\", \"drive\", \"MyDrive\", \"Colab Notebooks\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bSAcm0T0wgBe",
    "outputId": "a1d8afa7-859a-4893-8ed5-3a0aec1e4948"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fcca7bd3970>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/spacy/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fcca7bd3d60>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/spacy/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fcca7bd3eb0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/spacy/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fcca7bd3940>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/spacy/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fcca7b64ee0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/spacy/\u001b[0m\n",
      "Requirement already up-to-date: spacy[cuda102] in /home/deponce/anaconda3/lib/python3.8/site-packages (3.1.1)\n",
      "Requirement already satisfied, skipping upgrade: srsly<3.0.0,>=2.4.1 in /home/deponce/anaconda3/lib/python3.8/site-packages (from spacy[cuda102]) (2.4.1)\n",
      "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /home/deponce/anaconda3/lib/python3.8/site-packages (from spacy[cuda102]) (1.0.5)\n",
      "Requirement already satisfied, skipping upgrade: typer<0.4.0,>=0.3.0 in /home/deponce/anaconda3/lib/python3.8/site-packages (from spacy[cuda102]) (0.3.2)\n",
      "Requirement already satisfied, skipping upgrade: spacy-legacy<3.1.0,>=3.0.7 in /home/deponce/anaconda3/lib/python3.8/site-packages (from spacy[cuda102]) (3.0.8)\n",
      "Requirement already satisfied, skipping upgrade: thinc<8.1.0,>=8.0.8 in /home/deponce/anaconda3/lib/python3.8/site-packages (from spacy[cuda102]) (8.0.8)\n",
      "Requirement already satisfied, skipping upgrade: catalogue<2.1.0,>=2.0.4 in /home/deponce/anaconda3/lib/python3.8/site-packages (from spacy[cuda102]) (2.0.4)\n",
      "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.8.1 in /home/deponce/anaconda3/lib/python3.8/site-packages (from spacy[cuda102]) (0.8.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /home/deponce/.local/lib/python3.8/site-packages (from spacy[cuda102]) (1.19.5)\n",
      "Requirement already satisfied, skipping upgrade: blis<0.8.0,>=0.4.0 in /home/deponce/anaconda3/lib/python3.8/site-packages (from spacy[cuda102]) (0.7.4)\n",
      "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /home/deponce/.local/lib/python3.8/site-packages (from spacy[cuda102]) (2.25.1)\n",
      "Requirement already satisfied, skipping upgrade: jinja2 in /home/deponce/anaconda3/lib/python3.8/site-packages (from spacy[cuda102]) (2.11.2)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /home/deponce/anaconda3/lib/python3.8/site-packages (from spacy[cuda102]) (50.3.1.post20201107)\n",
      "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /home/deponce/.local/lib/python3.8/site-packages (from spacy[cuda102]) (4.56.0)\n",
      "Requirement already satisfied, skipping upgrade: pathy>=0.3.5 in /home/deponce/anaconda3/lib/python3.8/site-packages (from spacy[cuda102]) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /home/deponce/anaconda3/lib/python3.8/site-packages (from spacy[cuda102]) (3.0.5)\n",
      "Requirement already satisfied, skipping upgrade: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /home/deponce/anaconda3/lib/python3.8/site-packages (from spacy[cuda102]) (1.7.4)\n",
      "Requirement already satisfied, skipping upgrade: packaging>=20.0 in /home/deponce/anaconda3/lib/python3.8/site-packages (from spacy[cuda102]) (20.4)\n",
      "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /home/deponce/anaconda3/lib/python3.8/site-packages (from spacy[cuda102]) (2.0.5)\n",
      "Requirement already satisfied, skipping upgrade: cupy-cuda102<10.0.0,>=5.0.0b4; extra == \"cuda102\" in /home/deponce/anaconda3/lib/python3.8/site-packages (from spacy[cuda102]) (9.2.0)\n",
      "Requirement already satisfied, skipping upgrade: click<7.2.0,>=7.1.1 in /home/deponce/anaconda3/lib/python3.8/site-packages (from typer<0.4.0,>=0.3.0->spacy[cuda102]) (7.1.2)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.27,>=1.21.1 in /home/deponce/.local/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy[cuda102]) (1.26.3)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /home/deponce/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy[cuda102]) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /home/deponce/.local/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy[cuda102]) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: chardet<5,>=3.0.2 in /home/deponce/.local/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy[cuda102]) (4.0.0)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /home/deponce/anaconda3/lib/python3.8/site-packages (from jinja2->spacy[cuda102]) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: smart-open<6.0.0,>=5.0.0 in /home/deponce/anaconda3/lib/python3.8/site-packages (from pathy>=0.3.5->spacy[cuda102]) (5.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /home/deponce/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->spacy[cuda102]) (2.4.7)\n",
      "Requirement already satisfied, skipping upgrade: six in /home/deponce/.local/lib/python3.8/site-packages (from packaging>=20.0->spacy[cuda102]) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: fastrlock>=0.5 in /home/deponce/anaconda3/lib/python3.8/site-packages (from cupy-cuda102<10.0.0,>=5.0.0b4; extra == \"cuda102\"->spacy[cuda102]) (0.6)\n",
      "2021-08-06 17:03:48.785056: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/deponce/.local/lib/python3.8/site-packages/urllib3/connection.py\", line 169, in _new_conn\n",
      "    conn = connection.create_connection(\n",
      "  File \"/home/deponce/.local/lib/python3.8/site-packages/urllib3/util/connection.py\", line 73, in create_connection\n",
      "    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n",
      "  File \"/home/deponce/anaconda3/lib/python3.8/socket.py\", line 918, in getaddrinfo\n",
      "    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\n",
      "socket.gaierror: [Errno -3] Temporary failure in name resolution\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/deponce/.local/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 699, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/deponce/.local/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 382, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"/home/deponce/.local/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 1010, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"/home/deponce/.local/lib/python3.8/site-packages/urllib3/connection.py\", line 353, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/home/deponce/.local/lib/python3.8/site-packages/urllib3/connection.py\", line 181, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x7faebabbda90>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/deponce/.local/lib/python3.8/site-packages/requests/adapters.py\", line 439, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/deponce/.local/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 755, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/deponce/.local/lib/python3.8/site-packages/urllib3/util/retry.py\", line 573, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Max retries exceeded with url: /explosion/spacy-models/master/compatibility.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7faebabbda90>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/deponce/anaconda3/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/deponce/anaconda3/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/deponce/anaconda3/lib/python3.8/site-packages/spacy/__main__.py\", line 4, in <module>\n",
      "    setup_cli()\n",
      "  File \"/home/deponce/anaconda3/lib/python3.8/site-packages/spacy/cli/_util.py\", line 69, in setup_cli\n",
      "    command(prog_name=COMMAND)\n",
      "  File \"/home/deponce/anaconda3/lib/python3.8/site-packages/click/core.py\", line 829, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "  File \"/home/deponce/anaconda3/lib/python3.8/site-packages/click/core.py\", line 782, in main\n",
      "    rv = self.invoke(ctx)\n",
      "  File \"/home/deponce/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1259, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "  File \"/home/deponce/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1066, in invoke\n",
      "    return ctx.invoke(self.callback, **ctx.params)\n",
      "  File \"/home/deponce/anaconda3/lib/python3.8/site-packages/click/core.py\", line 610, in invoke\n",
      "    return callback(*args, **kwargs)\n",
      "  File \"/home/deponce/anaconda3/lib/python3.8/site-packages/typer/main.py\", line 497, in wrapper\n",
      "    return callback(**use_params)  # type: ignore\n",
      "  File \"/home/deponce/anaconda3/lib/python3.8/site-packages/spacy/cli/download.py\", line 35, in download_cli\n",
      "    download(model, direct, sdist, *ctx.args)\n",
      "  File \"/home/deponce/anaconda3/lib/python3.8/site-packages/spacy/cli/download.py\", line 67, in download\n",
      "    compatibility = get_compatibility()\n",
      "  File \"/home/deponce/anaconda3/lib/python3.8/site-packages/spacy/cli/download.py\", line 78, in get_compatibility\n",
      "    r = requests.get(about.__compatibility__)\n",
      "  File \"/home/deponce/.local/lib/python3.8/site-packages/requests/api.py\", line 76, in get\n",
      "    return request('get', url, params=params, **kwargs)\n",
      "  File \"/home/deponce/.local/lib/python3.8/site-packages/requests/api.py\", line 61, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "  File \"/home/deponce/.local/lib/python3.8/site-packages/requests/sessions.py\", line 542, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/deponce/.local/lib/python3.8/site-packages/requests/sessions.py\", line 655, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/deponce/.local/lib/python3.8/site-packages/requests/adapters.py\", line 516, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Max retries exceeded with url: /explosion/spacy-models/master/compatibility.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7faebabbda90>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-06 17:03:50.970589: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/deponce/.local/lib/python3.8/site-packages/urllib3/connection.py\", line 169, in _new_conn\n",
      "    conn = connection.create_connection(\n",
      "  File \"/home/deponce/.local/lib/python3.8/site-packages/urllib3/util/connection.py\", line 73, in create_connection\n",
      "    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n",
      "  File \"/home/deponce/anaconda3/lib/python3.8/socket.py\", line 918, in getaddrinfo\n",
      "    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\n",
      "socket.gaierror: [Errno -3] Temporary failure in name resolution\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/deponce/.local/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 699, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/deponce/.local/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 382, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"/home/deponce/.local/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 1010, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"/home/deponce/.local/lib/python3.8/site-packages/urllib3/connection.py\", line 353, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/home/deponce/.local/lib/python3.8/site-packages/urllib3/connection.py\", line 181, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x7f977ac0da90>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/deponce/.local/lib/python3.8/site-packages/requests/adapters.py\", line 439, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/deponce/.local/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 755, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/deponce/.local/lib/python3.8/site-packages/urllib3/util/retry.py\", line 573, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Max retries exceeded with url: /explosion/spacy-models/master/compatibility.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f977ac0da90>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/deponce/anaconda3/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/deponce/anaconda3/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/deponce/anaconda3/lib/python3.8/site-packages/spacy/__main__.py\", line 4, in <module>\n",
      "    setup_cli()\n",
      "  File \"/home/deponce/anaconda3/lib/python3.8/site-packages/spacy/cli/_util.py\", line 69, in setup_cli\n",
      "    command(prog_name=COMMAND)\n",
      "  File \"/home/deponce/anaconda3/lib/python3.8/site-packages/click/core.py\", line 829, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "  File \"/home/deponce/anaconda3/lib/python3.8/site-packages/click/core.py\", line 782, in main\n",
      "    rv = self.invoke(ctx)\n",
      "  File \"/home/deponce/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1259, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "  File \"/home/deponce/anaconda3/lib/python3.8/site-packages/click/core.py\", line 1066, in invoke\n",
      "    return ctx.invoke(self.callback, **ctx.params)\n",
      "  File \"/home/deponce/anaconda3/lib/python3.8/site-packages/click/core.py\", line 610, in invoke\n",
      "    return callback(*args, **kwargs)\n",
      "  File \"/home/deponce/anaconda3/lib/python3.8/site-packages/typer/main.py\", line 497, in wrapper\n",
      "    return callback(**use_params)  # type: ignore\n",
      "  File \"/home/deponce/anaconda3/lib/python3.8/site-packages/spacy/cli/download.py\", line 35, in download_cli\n",
      "    download(model, direct, sdist, *ctx.args)\n",
      "  File \"/home/deponce/anaconda3/lib/python3.8/site-packages/spacy/cli/download.py\", line 67, in download\n",
      "    compatibility = get_compatibility()\n",
      "  File \"/home/deponce/anaconda3/lib/python3.8/site-packages/spacy/cli/download.py\", line 78, in get_compatibility\n",
      "    r = requests.get(about.__compatibility__)\n",
      "  File \"/home/deponce/.local/lib/python3.8/site-packages/requests/api.py\", line 76, in get\n",
      "    return request('get', url, params=params, **kwargs)\n",
      "  File \"/home/deponce/.local/lib/python3.8/site-packages/requests/api.py\", line 61, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "  File \"/home/deponce/.local/lib/python3.8/site-packages/requests/sessions.py\", line 542, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/deponce/.local/lib/python3.8/site-packages/requests/sessions.py\", line 655, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/deponce/.local/lib/python3.8/site-packages/requests/adapters.py\", line 516, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Max retries exceeded with url: /explosion/spacy-models/master/compatibility.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f977ac0da90>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution'))\n"
     ]
    }
   ],
   "source": [
    "!pip install -U spacy[cuda102]\n",
    "!python -m spacy download en_core_web_sm\n",
    "!python -m spacy download zh_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "GEytdUzXwRMG"
   },
   "outputs": [],
   "source": [
    "from zh_dataset import ZhEnDataset, BaggingDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g3gPZgo4wRMG"
   },
   "source": [
    "\n",
    "Language Translation with nn.Transformer and torchtext\n",
    "======================================================\n",
    "\n",
    "This tutorial shows, how to train a translation model from scratch using\n",
    "Transformer. We will be using `Multi30k <http://www.statmt.org/wmt16/multimodal-task.html#task1>`__ \n",
    "dataset to train a German to English translation model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qHoHXyajwRMH"
   },
   "source": [
    "Data Sourcing and Processing\n",
    "----------------------------\n",
    "\n",
    "`torchtext library <https://pytorch.org/text/stable/>`__ has utilities for creating datasets that can be easily\n",
    "iterated through for the purposes of creating a language translation\n",
    "model. In this example, we show how to use torchtext's inbuilt datasets, \n",
    "tokenize a raw text sentence, build vocabulary, and numericalize tokens into tensor. We will use\n",
    "`Multi30k dataset from torchtext library <https://pytorch.org/text/stable/datasets.html#multi30k>`__\n",
    "that yields a pair of source-target raw sentences. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "mmo8vuj1wRMH"
   },
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.datasets import Multi30k\n",
    "from typing import Iterable, List\n",
    "\n",
    "\n",
    "SRC_LANGUAGE = 'en'\n",
    "TGT_LANGUAGE = 'zh'\n",
    "\n",
    "# Place-holders\n",
    "token_transform = {}\n",
    "vocab_transform = {}\n",
    "\n",
    "\n",
    "# Create source and target language tokenizer. Make sure to install the dependencies.\n",
    "# pip install -U spacy\n",
    "# python -m spacy download en_core_web_sm\n",
    "# python -m spacy download de_core_news_sm\n",
    "token_transform[SRC_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "token_transform[TGT_LANGUAGE] = get_tokenizer('spacy', language='zh_core_web_sm')\n",
    "\n",
    "\n",
    "# helper function to yield list of tokens\n",
    "def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n",
    "    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n",
    "\n",
    "    for data_sample in data_iter:\n",
    "        yield token_transform[language](data_sample[language_index[language]])\n",
    "\n",
    "# Define special symbols and indices\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
    "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
    " \n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    # Training data Iterator \n",
    "    train_iter = ZhEnDataset(split='train', start=0, end=150000)\n",
    "    # Create torchtext's Vocab object \n",
    "    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train_iter, ln),\n",
    "                                                    # min_freq=1,\n",
    "                                                    min_freq=3,\n",
    "                                                    specials=special_symbols,\n",
    "                                                    special_first=True)\n",
    "# Set UNK_IDX as the default index. This index is returned when the token is not found. \n",
    "# If not set, it throws RuntimeError when the queried token is not found in the Vocabulary. \n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    " vocab_transform[ln].set_default_index(UNK_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WsU-FWrzwRMJ"
   },
   "source": [
    "Seq2Seq Network using Transformer\n",
    "---------------------------------\n",
    "\n",
    "Transformer is a Seq2Seq model introduced in `“Attention is all you\n",
    "need” <https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf>`__\n",
    "paper for solving machine translation tasks. \n",
    "Below, we will create a Seq2Seq network that uses Transformer. The network\n",
    "consists of three parts. First part is the embedding layer. This layer converts tensor of input indices\n",
    "into corresponding tensor of input embeddings. These embedding are further augmented with positional\n",
    "encodings to provide position information of input tokens to the model. The second part is the \n",
    "actual `Transformer <https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html>`__ model. \n",
    "Finally, the output of Transformer model is passed through linear layer\n",
    "that give un-normalized probabilities for each token in the target language. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Transformer\n",
    "import math\n",
    "DEVICE = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "class PositionEmbedding_encoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 emb_size: int,\n",
    "                 maxlen: int = 500):\n",
    "        super(PositionEmbedding_encoder, self).__init__()\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
    "        self.pos_embedding = nn.TransformerEncoderLayer(d_model=emb_size,\n",
    "                                                   nhead=8,\n",
    "                                                   dim_feedforward=512,\n",
    "                                                   dropout=0.5\n",
    "                                                  ).to(DEVICE)\n",
    "        pos_c = nn.Parameter(torch.Tensor(maxlen, emb_size))\n",
    "        pos_c = pos_c.unsqueeze(-2)\n",
    "        self.register_buffer('pos_c', pos_c)\n",
    "        torch.nn.init.xavier_normal_(pos_c)\n",
    "    def forward(self, token_embedding: Tensor):\n",
    "        return token_embedding + self.pos_embedding(token_embedding) +self.pos_c[:token_embedding.size(0), :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionEmbedding_decoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 emb_size: int,\n",
    "                 maxlen: int = 500\n",
    "                ):\n",
    "        super(PositionEmbedding_decoder, self).__init__()\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
    "        \n",
    "        pos_c = nn.Parameter(torch.Tensor(maxlen, emb_size))\n",
    "        pos_c = pos_c.unsqueeze(-2)\n",
    "        self.register_buffer('pos_c', pos_c)\n",
    "        torch.nn.init.xavier_normal_(pos_c)\n",
    "    def forward(self, token_embedding: Tensor):\n",
    "        return token_embedding +self.pos_c[:token_embedding.size(0), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "SFo80khJwRMK"
   },
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Transformer\n",
    "import math\n",
    "\n",
    "\n",
    "# helper Module that adds positional encoding to the token embedding to introduce a notion of word order.\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,\n",
    "                 emb_size: int,\n",
    "                 dropout: float,\n",
    "                 maxlen: int = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding: Tensor):\n",
    "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
    "\n",
    "# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens: Tensor):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
    "\n",
    "# Seq2Seq Network \n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_encoder_layers: int,\n",
    "                 num_decoder_layers: int,\n",
    "                 emb_size: int,\n",
    "                 nhead: int,\n",
    "                 src_vocab_size: int,\n",
    "                 tgt_vocab_size: int,\n",
    "                 dim_feedforward: int = 512,\n",
    "                 dropout: float = 0.1):\n",
    "        super(Seq2SeqTransformer, self).__init__()\n",
    "        self.transformer = Transformer(d_model=emb_size,\n",
    "                                       nhead=nhead,\n",
    "                                       num_encoder_layers=num_encoder_layers,\n",
    "                                       num_decoder_layers=num_decoder_layers,\n",
    "                                       dim_feedforward=dim_feedforward,\n",
    "                                       dropout=dropout)\n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
    "        self.positional_encoding_encoder = PositionEmbedding_encoder(\n",
    "            emb_size)\n",
    "        self.positional_decoding_decoder = PositionEmbedding_decoder(\n",
    "            emb_size)\n",
    "    def forward(self,\n",
    "                src: Tensor,\n",
    "                trg: Tensor,\n",
    "                src_mask: Tensor,\n",
    "                tgt_mask: Tensor,\n",
    "                src_padding_mask: Tensor,\n",
    "                tgt_padding_mask: Tensor,\n",
    "                memory_key_padding_mask: Tensor):\n",
    "        src_emb = self.positional_encoding_encoder(self.src_tok_emb(src))\n",
    "        tgt_emb = self.positional_decoding_decoder(self.tgt_tok_emb(trg))\n",
    "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None, \n",
    "                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src: Tensor, src_mask: Tensor):\n",
    "        return self.transformer.encoder(self.positional_encoding_encoder(\n",
    "                            self.src_tok_emb(src)), src_mask)\n",
    "\n",
    "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
    "        return self.transformer.decoder(self.positional_decoding_decoder(\n",
    "                          self.tgt_tok_emb(tgt)), memory,\n",
    "                          tgt_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AoRbQezAwRMM"
   },
   "source": [
    "During training, we need a subsequent word mask that will prevent model to look into\n",
    "the future words when making predictions. We will also need masks to hide\n",
    "source and target padding tokens. Below, let's define a function that will take care of both. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "unF2JsfewRMN"
   },
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vH2a2irZwRMO"
   },
   "source": [
    "Let's now define the parameters of our model and instantiate the same. Below, we also \n",
    "define our loss function which is the cross-entropy loss and the optmizer used for training.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "_DIQF9vwwRMP"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
    "TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
    "\n",
    "EMB_SIZE = 512\n",
    "# EMB_SIZE = 128\n",
    "# EMB_SIZE = 64\n",
    "\n",
    "NHEAD = 8\n",
    "\n",
    "FFN_HID_DIM = 512\n",
    "# FFN_HID_DIM = 128\n",
    "# FFN_HID_DIM = 64\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "# BATCH_SIZE = 40\n",
    "\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 3\n",
    "\n",
    "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE, \n",
    "                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
    "\n",
    "for p in transformer.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "transformer = transformer.to(DEVICE)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "alvTPKm1wRMQ",
    "outputId": "1c930463-3b13-45ab-a3dc-8cdb69945078"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86605031"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "model_parameters = filter(lambda p: p.requires_grad, transformer.parameters())\n",
    "params = sum([np.prod(transformer.size()) for transformer in model_parameters])\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pNtAqwmowRMQ",
    "outputId": "c3ade393-315a-48c5-dc07-240db3227dc0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42548, 49383)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SRC_VOCAB_SIZE, TGT_VOCAB_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UmabUtoewRMR"
   },
   "source": [
    "Collation\n",
    "---------\n",
    "\n",
    "As seen in the ``Data Sourcing and Processing`` section, our data iterator yields a pair of raw strings. \n",
    "We need to convert these string pairs into the batched tensors that can be processed by our ``Seq2Seq`` network \n",
    "defined previously. Below we define our collate function that convert batch of raw strings into batch tensors that\n",
    "can be fed directly into our model.   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "x2N0VuotwRMR"
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# helper function to club together sequential operations\n",
    "def sequential_transforms(*transforms):\n",
    "    def func(txt_input):\n",
    "        for transform in transforms:\n",
    "            txt_input = transform(txt_input)\n",
    "        return txt_input\n",
    "    return func\n",
    "\n",
    "# function to add BOS/EOS and create tensor for input sequence indices\n",
    "def tensor_transform(token_ids: List[int]):\n",
    "    return torch.cat((torch.tensor([BOS_IDX]), \n",
    "                      torch.tensor(token_ids), \n",
    "                      torch.tensor([EOS_IDX])))\n",
    "\n",
    "# src and tgt language text transforms to convert raw strings into tensors indices\n",
    "text_transform = {}\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    text_transform[ln] = sequential_transforms(token_transform[ln], #Tokenization\n",
    "                                               vocab_transform[ln], #Numericalization\n",
    "                                               tensor_transform) # Add BOS/EOS and create tensor\n",
    "\n",
    "\n",
    "# function to collate data samples into batch tesors\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for src_sample, tgt_sample in batch:\n",
    "        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n",
    "        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
    "\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
    "    return src_batch, tgt_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpB7F-gtwRMS"
   },
   "source": [
    "Let's define training and evaluation loop that will be called for each \n",
    "epoch.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "59XQox9CwRMT"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def train_epoch(model, optimizer, train_iter):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "    \n",
    "    # train_iter = ZhEnDataset(split='train', start=15000, end=65000)\n",
    "    train_iter.resample()\n",
    "\n",
    "    train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "    \n",
    "    for src, tgt in train_dataloader:\n",
    "        # print(src.shape)\n",
    "        # print(tgt.shape)\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(train_dataloader)\n",
    "\n",
    "\n",
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "\n",
    "    val_iter = ZhEnDataset(split='valid', start=15000, end=25000)\n",
    "    val_dataloader = DataLoader(val_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "\n",
    "    for src, tgt in val_dataloader:\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "        \n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ew5Biw2LwRMU"
   },
   "source": [
    "Now we have all the ingredients to train our model. Let's do it!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate output sequence using greedy algorithm \n",
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    src = src.to(DEVICE)\n",
    "    src_mask = src_mask.to(DEVICE)\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(DEVICE)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
    "                    .type(torch.bool)).to(DEVICE)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.item()\n",
    "\n",
    "        ys = torch.cat([ys,\n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "\n",
    "# actual function to translate input sentence into target language\n",
    "def translate(model: torch.nn.Module, src_sentence: str):\n",
    "    model.eval()\n",
    "    src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n",
    "    num_tokens = src.shape[0]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    tgt_tokens = greedy_decode(\n",
    "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
    "    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "joxR16FLwRMV",
    "outputId": "2e7c336b-6b03-48a7-ca0c-a16139f7cd99",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train loss: 6.738, Val loss: 6.162, Epoch time = 326.819s\n",
      " 你 的 你 是 你 的 ， 你 的 ， 你 是\n",
      " 你 的 你 的 ？ 你 的 ？ 你 的 ？\n",
      " 在 <unk> 的 <unk> ， 在 <unk> 的 <unk> 的 <unk> ，\n",
      " 你 的 <unk> ， 你 的 <unk> ， 你 的 <unk> ， 你 会 会 会 会 会 会 会\n",
      " 你 的 <unk> ， 你 的 <unk> ， 你 的 <unk> ， 你 会 会 会 会 会 会 会\n",
      " 你 的 <unk> ， 你 的 <unk> ， 你 的 <unk> <unk> ， 你 的 <unk> <unk> <unk> <unk> 。\n",
      " 你 的 <unk> ， 你 的 <unk> <unk> <unk> <unk> ， 你 的 <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> 。 \n",
      "Epoch: 2, Train loss: 6.051, Val loss: 5.874, Epoch time = 325.989s\n",
      "Epoch: 3, Train loss: 5.837, Val loss: 5.706, Epoch time = 324.189s\n",
      "Epoch: 4, Train loss: 5.692, Val loss: 5.568, Epoch time = 325.471s\n",
      "Epoch: 5, Train loss: 5.582, Val loss: 5.468, Epoch time = 325.904s\n",
      "Epoch: 6, Train loss: 5.485, Val loss: 5.376, Epoch time = 323.587s\n",
      "Epoch: 7, Train loss: 5.402, Val loss: 5.311, Epoch time = 325.896s\n",
      "Epoch: 8, Train loss: 5.326, Val loss: 5.221, Epoch time = 325.107s\n",
      "Epoch: 9, Train loss: 5.268, Val loss: 5.155, Epoch time = 329.171s\n",
      "Epoch: 10, Train loss: 5.214, Val loss: 5.100, Epoch time = 325.550s\n",
      "Epoch: 11, Train loss: 5.169, Val loss: 5.049, Epoch time = 325.719s\n",
      " <unk> 是 你 需要 的 。 \n",
      " 你 如何 做 什么 ？ \n",
      " 中国 从 中国 到 英语 英语 英语 英语 英语 \n",
      " 请 您 的 应用 程序 ， 您 的 <unk> <unk> ， 并 将 其 应用 程序 的 应用 程序 。\n",
      " 为了 在 学校 的 <unk> ， 请 <unk> <unk> <unk> <unk> 。 \n",
      " 在 这个 项目 中 ， 你 的 人 了解 到 你 的 人 ， 帮助 你 的 人 。 \n",
      " 当 你 的 运动 时 ， 当 你 的 运动 时 ， 你 的 运动 或 <unk> 的 运动 。 \n",
      "Epoch: 12, Train loss: 5.113, Val loss: 5.010, Epoch time = 325.098s\n",
      "Epoch: 13, Train loss: 5.071, Val loss: 4.961, Epoch time = 324.863s\n",
      "Epoch: 14, Train loss: 5.022, Val loss: 4.920, Epoch time = 325.724s\n",
      "Epoch: 15, Train loss: 4.980, Val loss: 4.877, Epoch time = 324.992s\n",
      "Epoch: 16, Train loss: 4.958, Val loss: 4.847, Epoch time = 324.498s\n",
      "Epoch: 17, Train loss: 4.921, Val loss: 4.814, Epoch time = 323.219s\n",
      "Epoch: 18, Train loss: 4.898, Val loss: 4.787, Epoch time = 324.705s\n",
      "Epoch: 19, Train loss: 4.863, Val loss: 4.755, Epoch time = 326.266s\n",
      "Epoch: 20, Train loss: 4.830, Val loss: 4.736, Epoch time = 324.652s\n",
      "Epoch: 21, Train loss: 4.816, Val loss: 4.712, Epoch time = 326.273s\n",
      " <unk> 是 所有 的 。 \n",
      " 你 怎么 做 ？ \n",
      " 从 英语 到 英语 \n",
      " 请 将 此 应用 程序 <unk> ， 请 将 您 的 代码 <unk> 。 \n",
      " 要 继续 在 学校 内 ， 请 继续 继续 在 学校 内 ， 请 继续 继续 <unk> 。 \n",
      " 帮助 您 了解 这个 项目 ， 帮助 您 理解 这个 项目 的 帮助 。 \n",
      " 在 你 的 运动 中 ， 你 的 运动 或 在 你 的 时间 内 ， 或者 在 你 的 时间 内 ， 或者 在 你\n",
      "Epoch: 22, Train loss: 4.799, Val loss: 4.692, Epoch time = 325.800s\n",
      "Epoch: 23, Train loss: 4.778, Val loss: 4.675, Epoch time = 326.474s\n",
      "Epoch: 24, Train loss: 4.764, Val loss: 4.655, Epoch time = 324.073s\n",
      "Epoch: 25, Train loss: 4.745, Val loss: 4.639, Epoch time = 327.827s\n",
      "Epoch: 26, Train loss: 4.722, Val loss: 4.618, Epoch time = 323.965s\n",
      "Epoch: 27, Train loss: 4.713, Val loss: 4.599, Epoch time = 324.947s\n",
      "Epoch: 28, Train loss: 4.693, Val loss: 4.591, Epoch time = 325.508s\n",
      "Epoch: 29, Train loss: 4.687, Val loss: 4.573, Epoch time = 326.085s\n",
      "Epoch: 30, Train loss: 4.662, Val loss: 4.562, Epoch time = 323.730s\n",
      "Epoch: 31, Train loss: 4.648, Val loss: 4.540, Epoch time = 325.619s\n",
      " 你 需要 所有 的 人 。 \n",
      " 你 怎么 做 ？ \n",
      " 从 这 一点 到 中国 。 \n",
      " 请 把 这个 代码 <unk> 到 您 的 应用 程序 中 ， 请 参阅   参考 资料 。 \n",
      " 请 继续 您 的 <unk> ， 请 继续 在 <unk> <unk> <unk> 。 \n",
      " 帮助 您 了解 项目 的 项目 ， 以 帮助 您 了解 项目 的 项目 。 \n",
      " 在 你 的 运动 时 ， 你 的 运动 或 运动 时 ， 在 你 的 运动 中 ， 可以 在 你 的 运动 。 \n",
      "Epoch: 32, Train loss: 4.631, Val loss: 4.532, Epoch time = 324.613s\n",
      "Epoch: 33, Train loss: 4.628, Val loss: 4.514, Epoch time = 327.393s\n",
      "Epoch: 34, Train loss: 4.605, Val loss: 4.499, Epoch time = 325.207s\n",
      "Epoch: 35, Train loss: 4.600, Val loss: 4.488, Epoch time = 265.766s\n",
      "Epoch: 36, Train loss: 4.580, Val loss: 4.478, Epoch time = 249.712s\n",
      "Epoch: 37, Train loss: 4.567, Val loss: 4.462, Epoch time = 249.314s\n",
      "Epoch: 38, Train loss: 4.561, Val loss: 4.459, Epoch time = 249.857s\n",
      "Epoch: 39, Train loss: 4.551, Val loss: 4.438, Epoch time = 251.615s\n",
      "Epoch: 40, Train loss: 4.539, Val loss: 4.430, Epoch time = 249.356s\n",
      "Epoch: 41, Train loss: 4.527, Val loss: 4.416, Epoch time = 249.896s\n",
      " 注意 所有 的 都 是 你 需要 的 。 \n",
      " 你 怎么 做 ？ \n",
      " 从 这 一 英语 到 中国 \n",
      " 请 将 这个 代码 <unk> ， 并 将 它 <unk> 应用 程序 。 \n",
      " 要 在 你 的 学校 里 选择 你 的 <unk> ， 请 继续 <unk> 。 \n",
      " 帮助 你 的 项目 添加 一个 项目 ， 并 理解 您 的 项目 中 的 兴趣 。 \n",
      " 当 你 在 你 的 时候 ， 你 的 传感器 或 在 你 的 <unk> 时 ， 你 的 <unk> <unk> <unk> 。 \n",
      "Epoch: 42, Train loss: 4.524, Val loss: 4.410, Epoch time = 249.711s\n",
      "Epoch: 43, Train loss: 4.505, Val loss: 4.400, Epoch time = 251.079s\n",
      "Epoch: 44, Train loss: 4.492, Val loss: 4.381, Epoch time = 250.277s\n",
      "Epoch: 45, Train loss: 4.480, Val loss: 4.374, Epoch time = 250.704s\n",
      "Epoch: 46, Train loss: 4.460, Val loss: 4.360, Epoch time = 250.253s\n",
      "Epoch: 47, Train loss: 4.461, Val loss: 4.358, Epoch time = 249.437s\n",
      "Epoch: 48, Train loss: 4.461, Val loss: 4.351, Epoch time = 249.020s\n",
      "Epoch: 49, Train loss: 4.449, Val loss: 4.339, Epoch time = 250.802s\n",
      "Epoch: 50, Train loss: 4.430, Val loss: 4.328, Epoch time = 251.357s\n",
      "Epoch: 51, Train loss: 4.421, Val loss: 4.322, Epoch time = 248.525s\n",
      " 注意 所有 的 都 是 你 需要 的 。 \n",
      " 你 怎么 做 ？ \n",
      " <unk> 从 这 一 英语 中 <unk> \n",
      " 请 将 此 应用 程序 复制 到 您 的 代码 中 ， 并 将 其 复制 到 您 的 应用\n",
      " 为了 继续 在 学校 ， 请 继续 选择 您 的 <unk> 。 \n",
      " 帮助 人们 了解 您 的 项目 ， 添加 了 您 对 项目 的 兴趣 。 \n",
      " 当 你 的 <unk> <unk> 或 <unk> 时 ， 你 的 <unk> <unk> <unk> 。 \n",
      "Epoch: 52, Train loss: 4.419, Val loss: 4.307, Epoch time = 249.720s\n",
      "Epoch: 53, Train loss: 4.407, Val loss: 4.302, Epoch time = 249.462s\n",
      "Epoch: 54, Train loss: 4.413, Val loss: 4.291, Epoch time = 249.759s\n",
      "Epoch: 55, Train loss: 4.400, Val loss: 4.287, Epoch time = 249.166s\n",
      "Epoch: 56, Train loss: 4.391, Val loss: 4.283, Epoch time = 248.771s\n",
      "Epoch: 57, Train loss: 4.381, Val loss: 4.271, Epoch time = 249.360s\n",
      "Epoch: 58, Train loss: 4.369, Val loss: 4.269, Epoch time = 249.688s\n",
      "Epoch: 59, Train loss: 4.367, Val loss: 4.260, Epoch time = 250.306s\n",
      "Epoch: 60, Train loss: 4.365, Val loss: 4.249, Epoch time = 247.867s\n",
      "Epoch: 61, Train loss: 4.351, Val loss: 4.256, Epoch time = 250.205s\n",
      " 注意 你 需要 的 所有 。 \n",
      " 你 怎么 做 ？ \n",
      " 从 这 一 英语 到 中国 \n",
      " 请 把 这 份 代码 复制 到 您 的 应用 程序 中 ， 请 把 它 复制 到 您 的\n",
      " 要 继续 你 的 学校 ， 请 继续 你 的 账户 。 \n",
      " 帮助 您 了解 这个 项目 的 添加 了 一个 项目 ， 并 在 您 的 项目 中 添加 了 一个\n",
      " 当 你 的 实时 传感器 或 传感器 时 ， 你 的 实时 传感器 会 被 通知 。 \n",
      "Epoch: 62, Train loss: 4.352, Val loss: 4.238, Epoch time = 250.779s\n",
      "Epoch: 63, Train loss: 4.351, Val loss: 4.233, Epoch time = 251.387s\n",
      "Epoch: 64, Train loss: 4.336, Val loss: 4.231, Epoch time = 249.701s\n",
      "Epoch: 65, Train loss: 4.330, Val loss: 4.223, Epoch time = 248.933s\n",
      "Epoch: 66, Train loss: 4.322, Val loss: 4.222, Epoch time = 250.227s\n",
      "Epoch: 67, Train loss: 4.319, Val loss: 4.214, Epoch time = 248.928s\n",
      "Epoch: 68, Train loss: 4.317, Val loss: 4.208, Epoch time = 250.308s\n",
      "Epoch: 69, Train loss: 4.308, Val loss: 4.204, Epoch time = 248.162s\n",
      "Epoch: 70, Train loss: 4.297, Val loss: 4.197, Epoch time = 250.025s\n",
      "Epoch: 71, Train loss: 4.299, Val loss: 4.190, Epoch time = 249.592s\n",
      " 注意 。 你 需要 所有 的 。 \n",
      " 你 怎么 做 ？ \n",
      " <unk> <unk> <unk> \n",
      " 请 把 这个 代码 复制 到 你 的 应用 程序 ， 然后 复制 它 。 \n",
      " 请 继续 选择 你 的 学校 ， 请 继续 在 你 的 学校 里 选择 。 \n",
      " 帮助 人们 了解 这个 项目 ， 通过 添加 一个 项目 ， 了解 您 的 项目 中 的 兴趣 。 \n",
      " 获取 实时 的 传感器 或 传感器 ， 当 你 的 <unk> 时 ， 你 的 <unk> <unk> 。 \n",
      "Epoch: 72, Train loss: 4.300, Val loss: 4.185, Epoch time = 250.802s\n",
      "Epoch: 73, Train loss: 4.286, Val loss: 4.184, Epoch time = 249.157s\n",
      "Epoch: 74, Train loss: 4.281, Val loss: 4.179, Epoch time = 249.249s\n",
      "Epoch: 75, Train loss: 4.270, Val loss: 4.172, Epoch time = 248.058s\n",
      "Epoch: 76, Train loss: 4.270, Val loss: 4.166, Epoch time = 249.946s\n",
      "Epoch: 77, Train loss: 4.278, Val loss: 4.165, Epoch time = 249.612s\n",
      "Epoch: 78, Train loss: 4.263, Val loss: 4.158, Epoch time = 250.073s\n",
      "Epoch: 79, Train loss: 4.255, Val loss: 4.158, Epoch time = 249.847s\n",
      "Epoch: 80, Train loss: 4.261, Val loss: 4.154, Epoch time = 248.884s\n",
      "Epoch: 81, Train loss: 4.256, Val loss: 4.148, Epoch time = 250.830s\n",
      " 注意 ： 你 需要 你 的 一切 。 \n",
      " 你 怎么 做 ？ \n",
      " 中国 英语 从 这 一 英语 到 了 \n",
      " 请 将 此 开关 复制 到 您 的 应用 程序 中 ， 并 将 它 复制 到 您 的 代码\n",
      " 要 继续 你 的 学校 ， 请 继续 签署 你 的 帐户 。 \n",
      " 帮助 您 理解 这个 项目 的 <unk> ， 帮助 人们 理解 这个 项目 。 \n",
      " 在 你 的 实时 的 时候 ， 你 的 <unk> - <unk> - <unk> - <unk> - <unk> - <unk> - <unk> - <unk> - <unk>\n",
      "Epoch: 82, Train loss: 4.244, Val loss: 4.148, Epoch time = 249.193s\n",
      "Epoch: 83, Train loss: 4.240, Val loss: 4.142, Epoch time = 251.415s\n",
      "Epoch: 84, Train loss: 4.233, Val loss: 4.142, Epoch time = 249.509s\n",
      "Epoch: 85, Train loss: 4.244, Val loss: 4.133, Epoch time = 250.498s\n",
      "Epoch: 86, Train loss: 4.226, Val loss: 4.128, Epoch time = 248.926s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 87, Train loss: 4.217, Val loss: 4.124, Epoch time = 250.399s\n",
      "Epoch: 88, Train loss: 4.224, Val loss: 4.118, Epoch time = 249.817s\n",
      "Epoch: 89, Train loss: 4.222, Val loss: 4.115, Epoch time = 249.465s\n",
      "Epoch: 90, Train loss: 4.208, Val loss: 4.120, Epoch time = 248.819s\n",
      "Epoch: 91, Train loss: 4.204, Val loss: 4.110, Epoch time = 249.445s\n",
      " 注意 ， 你 需要 所有 的 。 \n",
      " 你 在 做 什么 ？ \n",
      " 中国 的 英语 从 这 条 <unk> \n",
      " 请 将 它 复制 到 您 的 应用 程序 ， 并 将 它 复制 到 您 的 应用 程序 。\n",
      " 请 继续 你 的 学校 ， 请 继续 你 的 学校 ， 请 继续 <unk> 。 \n",
      " 帮助 人们 理解 这个 项目 的 <unk> <unk> <unk> <unk> <unk> 。 \n",
      " 在 你 的 实时 传感器 或 实时 的 <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> 。 \n",
      "Epoch: 92, Train loss: 4.202, Val loss: 4.105, Epoch time = 249.336s\n",
      "Epoch: 93, Train loss: 4.213, Val loss: 4.100, Epoch time = 249.808s\n",
      "Epoch: 94, Train loss: 4.196, Val loss: 4.098, Epoch time = 250.947s\n",
      "Epoch: 95, Train loss: 4.195, Val loss: 4.086, Epoch time = 251.175s\n",
      "Epoch: 96, Train loss: 4.194, Val loss: 4.085, Epoch time = 250.451s\n",
      "Epoch: 97, Train loss: 4.180, Val loss: 4.085, Epoch time = 250.866s\n",
      "Epoch: 98, Train loss: 4.188, Val loss: 4.085, Epoch time = 250.223s\n",
      "Epoch: 99, Train loss: 4.176, Val loss: 4.067, Epoch time = 250.745s\n",
      "Epoch: 100, Train loss: 4.170, Val loss: 4.072, Epoch time = 249.757s\n",
      "Epoch: 101, Train loss: 4.178, Val loss: 4.069, Epoch time = 249.811s\n",
      " 注意 所有 的 都 是 你 需要 的 。 \n",
      " 你 怎么 做 ？ \n",
      " 从 这 一 英语 到 <unk> \n",
      " 请 将 这个 开关 复制 到 您 的 应用 程序 中 ， 并 将 它 复制 到 它 。 \n",
      " 要 继续 <unk> ， 请 继续 在 学校 里 选择 你 的 账户 。 \n",
      " 帮助 <unk> 理解 这个 项目 的 人 ， 帮助 你 理解 这个 项目 。 \n",
      " 在 你 的 传感器 或 传感器 时 ， 请 在 你 的 实时 通知 <unk> <unk> <unk> <unk> <unk> 。 \n",
      "Epoch: 102, Train loss: 4.160, Val loss: 4.061, Epoch time = 250.474s\n",
      "Epoch: 103, Train loss: 4.159, Val loss: 4.056, Epoch time = 249.678s\n",
      "Epoch: 104, Train loss: 4.167, Val loss: 4.050, Epoch time = 249.966s\n",
      "Epoch: 105, Train loss: 4.149, Val loss: 4.051, Epoch time = 248.956s\n",
      "Epoch: 106, Train loss: 4.154, Val loss: 4.052, Epoch time = 249.027s\n",
      "Epoch: 107, Train loss: 4.148, Val loss: 4.053, Epoch time = 249.296s\n",
      "Epoch: 108, Train loss: 4.138, Val loss: 4.047, Epoch time = 251.179s\n",
      "Epoch: 109, Train loss: 4.152, Val loss: 4.042, Epoch time = 249.644s\n",
      "Epoch: 110, Train loss: 4.149, Val loss: 4.038, Epoch time = 250.160s\n",
      "Epoch: 111, Train loss: 4.136, Val loss: 4.035, Epoch time = 249.945s\n",
      " 注意 所有 的 人 都 是 你 需要 的 。 \n",
      " 你 是 怎么 做 的 ？ \n",
      " 中国 的 英语 从 <unk> 到 <unk> \n",
      " 请 把 它 复制 到 你 的 应用 程序 ， 并 将 它 复制 到 你 的 代码 。 \n",
      " 为了 继续 你 的 学校 ， 请 继续 你 的 帐户 。 \n",
      " 帮助 您 了解 这个 项目 的 人 ， 通过 添加 一个 <unk> 项目 来 了解 您 的 项目 。 \n",
      " 在 实时 的 时候 ， 你 的 传感器 或 传感器 会 在 实时 的 时候 发出 通知 。 \n",
      "Epoch: 112, Train loss: 4.123, Val loss: 4.034, Epoch time = 249.739s\n",
      "Epoch: 113, Train loss: 4.121, Val loss: 4.022, Epoch time = 249.915s\n",
      "Epoch: 114, Train loss: 4.132, Val loss: 4.026, Epoch time = 251.228s\n",
      "Epoch: 115, Train loss: 4.116, Val loss: 4.017, Epoch time = 249.374s\n",
      "Epoch: 116, Train loss: 4.117, Val loss: 4.023, Epoch time = 250.149s\n",
      "Epoch: 117, Train loss: 4.107, Val loss: 4.012, Epoch time = 249.753s\n",
      "Epoch: 118, Train loss: 4.125, Val loss: 4.018, Epoch time = 251.722s\n",
      "Epoch: 119, Train loss: 4.112, Val loss: 4.018, Epoch time = 250.487s\n",
      "Epoch: 120, Train loss: 4.117, Val loss: 4.001, Epoch time = 250.569s\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "NUM_EPOCHS = 120\n",
    "train_iter = BaggingDataset(size=25000)\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = timer()\n",
    "    train_loss = train_epoch(transformer, optimizer, train_iter)\n",
    "    end_time = timer()\n",
    "    val_loss = evaluate(transformer)\n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
    "    if (epoch-1)%5 ==0:\n",
    "        \n",
    "        PATH = \"./models/bagging-150k-512-8-512ebmedding_trans_asy.pt\"\n",
    "        torch.save(transformer.state_dict(), PATH)\n",
    "        if (epoch-1)%10 ==0:\n",
    "            print(translate(transformer, \"Attention is all you need.\"))\n",
    "            print(translate(transformer, \"How are you doing?\"))\n",
    "            print(translate(transformer, \"Translate this from English to Chinese\"))\n",
    "            print(translate(transformer, \"Please copy this code, switch to your application and paste it there.\"))\n",
    "            print(translate(transformer, \"To continue signing in to your Crowdmark account, please select your school.\"))\n",
    "            print(translate(transformer, \"Help people interested in this repository understand your project by adding a README.\"))\n",
    "            print(translate(transformer, \"Get notified in real-time when visitors press your doorbell or trigger the built-in motion sensors.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Zf0M2D7wRMW",
    "outputId": "3293aa35-ec98-463b-c586-d84574fcf1e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 注意 ， 你 需要 所有 的 人 。 \n",
      " 你 是 怎么 做 的 ？ \n",
      " 从 这 一 英语 到 中国 \n",
      " 请 将 此 代码 复制 到 您 的 应用 程序 中 ， 并 将 其 复制 到 您 的 应用\n",
      " 要 继续 您 的 学校 ， 请 继续 选择 您 的 学校 帐户 。 \n",
      " 帮助 您 了解 这个 项目 的 人 ， 帮助 您 了解 这个 项目 。 \n",
      " 在 你 的 传感器 上 ， 当 你 的 游客 通知 时 ， 或者 在 你 的 传感器 上 建立 实时 的 传感器 。 \n"
     ]
    }
   ],
   "source": [
    "print(translate(transformer, \"Attention is all you need.\"))\n",
    "print(translate(transformer, \"How are you doing?\"))\n",
    "print(translate(transformer, \"Translate this from English to Chinese\"))\n",
    "print(translate(transformer, \"Please copy this code, switch to your application and paste it there.\"))\n",
    "print(translate(transformer, \"To continue signing in to your Crowdmark account, please select your school.\"))\n",
    "print(translate(transformer, \"Help people interested in this repository understand your project by adding a README.\"))\n",
    "print(translate(transformer, \"Get notified in real-time when visitors press your doorbell or trigger the built-in motion sensors.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 注意 ， 你 需要 所有 的 人 。 '"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(transformer, \"Attention is all you need.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTorTDFBwRMX"
   },
   "source": [
    "References\n",
    "----------\n",
    "\n",
    "1. Attention is all you need paper.\n",
    "   https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf\n",
    "2. The annotated transformer. https://nlp.seas.harvard.edu/2018/04/03/attention.html#positional-encoding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "StNeeejewRMY"
   },
   "outputs": [],
   "source": [
    "PATH = \"./models/bagging-150k-512-8-512ebmedding_trans_asy.pt\"\n",
    "torch.save(transformer.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1hoVWqF4wRMY"
   },
   "outputs": [],
   "source": [
    "PATH = \"./models/bagging-150k-512-8-512ebmedding_trans_asy.pt\"\n",
    "transformer.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "translation_transformer-zh-bagging.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "4873a7689abbfe95ed7a782bdc9fbe47e51b46b20bbffcabe5affe94a27c270b"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
